# -*- coding: utf-8 -*-
"""Fake currency identfication.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ilkkCE2x8CpWoHHcNlnYGkRQaEzXnrwV
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

# Define image dimensions for preprocessing
height = 300
width = 300

# Define directories for training and validation data
train_dir = "/content/drive/MyDrive/5_Currencies_Dataset/Training"
validation_dir = "/content/drive/MyDrive/5_Currencies_Dataset/Valid"

# Number of batches for data generators
batch_size = 16

# Data augmentation for training images
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,  # Use '=' instead of '-'
    rotation_range=90,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True
)

# Data generator for validation images (no augmentation, only preprocessing)
validation_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

# Generate batches of data from the directories
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(height, width),
    batch_size=batch_size,
    class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(height, width),
    batch_size=batch_size,
    class_mode='categorical'
)

# Data augmentation for validation images
validation_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

# Creating data generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(height, width),
    batch_size=batch_size,
    class_mode='binary'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,  # Corrected from "validation dir"
    target_size=(height, width),
    batch_size=batch_size,
    class_mode='binary'
)

# Base model: EfficientNetB0
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(height, width, 3))

# Add custom top layers for classification
x = base_model.output
x = Flatten()(x)
x = Dense(1024, activation='relu')(x)
x = Dropout(0.5)(x)  # Fixed Dropout syntax
predictions = Dense(1, activation='sigmoid')(x)

# Combine base model with custom top layers
finetune_model = Model(inputs=base_model.input, outputs=predictions)  # Fixed model creation syntax

# Compile the model
finetune_model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Define callbacks
checkpoint = ModelCheckpoint(
    'best_model_2000.keras', monitor='val_accuracy', save_best_only=True, mode='max'
)  # Fixed 'ModelCheckpoint' spelling
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)  # Fixed ReduceLROnPlateau

# Train the model
history = finetune_model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size,
    epochs=50,
    callbacks=[checkpoint, early_stopping, reduce_lr]
)

# Print the final training and validation accuracy
train_acc = history.history['accuracy'][-1] * 100  # Fixed indexing and percentage calculation
val_acc = history.history['val_accuracy'][-1] * 100
print(f"Final Training Accuracy: {train_acc:.2f}%")
print(f"Final Validation Accuracy: {val_acc:.2f}%")

# Plot training and validation accuracy
plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.imagenet_utils import preprocess_input

# Plot training and validation accuracy over epochs
def plot_training_history(history):
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    if 'val_accuracy' in history.history:
        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()

    # Plot training and validation loss over epochs
    plt.plot(history.history['loss'], label='Training Loss')
    if 'val_loss' in history.history:
        plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()

# Testing the model
def predict_image(model, img_path, height, width):
    # Load and preprocess the image
    img = image.load_img(img_path, target_size=(height, width))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    # Predict using the model
    prediction = model.predict(img_array)

    # Interpret the prediction
    if prediction[0][0] > 0.5:
        return "Real"
    else:
        return "Fake"

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.imagenet_utils import preprocess_input

# Function to preprocess and predict the image
def predict_image(model, img_path, height, width):
    # Load the image with the target size
    img = image.load_img(img_path, target_size=(height, width))
    # Convert the image to an array
    img_array = image.img_to_array(img)
    # Expand dimensions to fit the model's input shape
    img_array = np.expand_dims(img_array, axis=0)
    # Preprocess the image
    img_array = preprocess_input(img_array)
    # Predict using the model
    prediction = model.predict(img_array)
    # Return the prediction (rounded)
    return "Fake" if prediction[0][0] >= 0.5 else "Real"

# Specify the image path for testing
test_img_path = "/content/drive/MyDrive/5_Currencies_Dataset/Valid/Fake_1 (7).jpg"

# Load and display the image
img = image.load_img(test_img_path)
plt.imshow(img)

# Get image dimensions
img_width, img_height = img.size

# Predict the image and display the prediction
prediction = predict_image(finetune_model, test_img_path, height=300, width=300)

# Use plt.text to add the prediction on the image
plt.text(
    img_width - 160,
    10,
    f'Prediction: {prediction}',
    fontsize=12,
    color='white',
    weight='bold',
    bbox=dict(facecolor='red', alpha=0.5)
)

# Show the modified plot
plt.show()

# Print the prediction in the console
print("Prediction:", prediction)

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.imagenet_utils import preprocess_input

# Function to preprocess and predict the image
def predict_image(model, img_path, height, width):
    # Load the image with the target size
    img = image.load_img(img_path, target_size=(height, width))
    # Convert the image to an array
    img_array = image.img_to_array(img)
    # Expand dimensions to fit the model's input shape
    img_array = np.expand_dims(img_array, axis=0)
    # Preprocess the image
    img_array = preprocess_input(img_array)
    # Predict using the model
    prediction = model.predict(img_array)
    # Return the prediction (rounded)
    return "Real" if prediction[0][0] >= 0.5 else "Fake"

# Specify the image path for testing
test_img_path = "/content/drive/MyDrive/5_Currencies_Dataset/Valid/Fake_1 (1).jpg"

# Load and display the image
img = image.load_img(test_img_path)
plt.imshow(img)

# Get image dimensions
img_width, img_height = img.size

# Predict the image and display the prediction
prediction = predict_image(finetune_model, test_img_path, height=224, width=224)

# Use plt.text to add the prediction on the image
plt.text(
    img_width - 160,
    10,
    f'Prediction: {prediction}',
    fontsize=12,
    color='white',
    weight='bold',
    bbox=dict(facecolor='red', alpha=0.5),
)

# Show the modified plot
plt.show()

# Print the prediction in the console
print("Prediction:", prediction)





import numpy as np from tensorflow.keras.preprocessing import image
# Function to preprocess and predict the image
def predict_ image(model, img_path):
# Load the image with the target size
img = image.load_img(img_path, target_size=(height, width))
# Convert the image to an array
img_array = image. img_to_array (img)
# Expand dimensions to fit the model's input shape
img_array = np-expand_dims(img_array, axis=0)
# Preprocess the image
img_array = preprocess_input(img_array)
# Predict using the model
prediction = model predict(img_array)
# Return the prediction (rounded)
return "Real" if prediction[0][0] >= 0.5 else "Fake"
# Specify the image path for testing
test_img_path = "/content/drive/MyDrive/MINIPROJECT/2000 Rs/Dataset (2000)/Testing/Fake/fake 1. jP®️"
# Load and display the image
img = image.load_img(test_img_path)
plt. imshow(img)
# Predict the image and display the prediction
prediction = predict_image(finetune_model, test_img_path)
# Get image dimensions
img width, img_height = img. size
# Use plt.text to add the prediction on the image
plt.text(img_width - 160, 10, 'Prediction: (prediction)', fontsize=12, color='white', weight= 'bold', bbox=dict(facecolor='red', alpha=0.5))
# Show the modified plot
plt. show(
# Print the prediction in the console
print("Prediction:", prediction)

import numpy as np from tensorflow.keras.preprocessing import image
# Function to preprocess and predict the image
def predict_image(model, img_path):
# Load the image with the target size
img = image.load_img(img_path, target_size=(height, width))
# Convert the image to
an array# Eonvert the image to an arrey
img_array = image.img_to_array(ing)
# Expordcdimensions te fit the model's input shape
ing_array = np.expand_dims(img_array, axis=0)
# Preprocess the image
img_apray = preprocess_inpot(img_array)
# Prediot using the todel
prediction = model predict(ing array)
# Reture ihe prediction (rounded)
cetana "Real" if prediction[el[0] >= 0,5 else "Fake"
# Specify the image path for resting
test_img_path: = "/content/drive/MyDrive/MINIPROJELT/2000 Rs/Dataset (2000) /Testing/Real/1.png"
# Load. and display the image
img = image. load_img(test_ing_path)
plt. imshow (ing)
# Predict the image and display the prediction
prediction = predict_image(finetune_model, test_img_path)
# Get image dimensions
ing width, img_height = ing. size

# Use plt.text to add the prediction on the image
plt. text(img_width - 160, 10, 'Prediction: (prediction)', fontsize=12, color='white', weight='bold', bbox=dict (facecolor='red', alpha=0,5))
# Sho the nortifiad plut
plt. show)
# Print the prediction in the console
print ("Prediction;", prediction)

import numpy as np from tensorflow.keras.preprocessing import image
# Function to preprocess and predict the image
def predict_image(model, img_path):
# Load the image with the target size
img = image.load_img(img_path, target_size=(height, width))
# Convert the image to an array
img_array = image. img_to_array(img)